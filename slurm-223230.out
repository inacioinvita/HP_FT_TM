CUDA available? False
Device count: 0
[INFO|2025-01-14 14:18:53] llamafactory.cli:157 >> Initializing distributed tasks at: localhost:34511
Traceback (most recent call last):
  File "/home/ivieira/miniconda3/envs/lf-env/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.5.1', 'console_scripts', 'torchrun')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 696, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 849, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 668, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: The server socket has failed to listen on any local network address. port: 34511, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
E0114 14:18:56.210000 152070 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 152075) of binary: /home/ivieira/miniconda3/envs/lf-env/bin/python
E0114 14:18:56.219000 152070 site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py:141] no error file defined for parent, to copy child error file (/tmp/torchelastic_u1fvw33k/c4e76762-dc32-421e-b331-41484084761f_z2gzp4fg/attempt_0/0/error.json)
Traceback (most recent call last):
  File "/home/ivieira/miniconda3/envs/lf-env/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.5.1', 'console_scripts', 'torchrun')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ivieira/miniconda3/envs/lf-env/bin/llamafactory-cli FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-14_14:18:54
  host      : g106.grove.adaptcentre.ie
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 152075)
  error_file: /tmp/torchelastic_u1fvw33k/c4e76762-dc32-421e-b331-41484084761f_z2gzp4fg/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 919, in main
      run(args)
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 910, in run
      elastic_launch(
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
      return launch_agent(self._config, self._entrypoint, list(args))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
      result = agent.run()
               ^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
      result = f(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 696, in run
      result = self._invoke_run(role)
               ^^^^^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 849, in _invoke_run
      self._initialize_workers(self._worker_group)
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
      result = f(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 668, in _initialize_workers
      self._rendezvous(worker_group)
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
      result = f(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
      rdzv_info = spec.rdzv_handler.next_rendezvous()
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
      self._store = TCPStore(  # type: ignore[call-arg]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  RuntimeError: The server socket has failed to listen on any local network address. port: 34511, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
  
============================================================
----------------------------------------
Model and checkpoint locations:
Base directory: /home/ivieira/LLaMA-Factory/
Model save path: /home/ivieira/LLaMA-Factory/saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-14-18-56
Checkpoint directory: /home/ivieira/LLaMA-Factory/saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-14-18-56/checkpoint-*
----------------------------------------
