  File "<string>", line 1
    import torch; print('CUDA available?', torch.cuda.is_available()); print('Device count:', torch.cuda.device_count()); print(Distributed
                                                                                                                               ^
SyntaxError: '(' was never closed
W0114 13:12:11.637000 149379 site-packages/torch/distributed/run.py:793] 
W0114 13:12:11.637000 149379 site-packages/torch/distributed/run.py:793] *****************************************
W0114 13:12:11.637000 149379 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0114 13:12:11.637000 149379 site-packages/torch/distributed/run.py:793] *****************************************
[INFO|2025-01-14 13:12:35] llamafactory.cli:157 >> Initializing distributed tasks at: localhost:35061
Traceback (most recent call last):
  File "/home/ivieira/miniconda3/envs/lf-env/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.5.1', 'console_scripts', 'torchrun')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 696, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 849, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 668, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: The server socket has failed to listen on any local network address. port: 35061, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
Traceback (most recent call last):
  File "/home/ivieira/miniconda3/envs/lf-env/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.5.1', 'console_scripts', 'torchrun')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 696, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 849, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 668, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: The server socket has failed to listen on any local network address. port: 35061, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
E0114 13:12:40.376000 149379 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 149386) of binary: /home/ivieira/miniconda3/envs/lf-env/bin/python
E0114 13:12:40.397000 149379 site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py:141] no error file defined for parent, to copy child error file (/tmp/torchelastic_97ytn305/27858b3c-92c4-4b49-9cf9-63c8e842da7e_f8057j6g/attempt_0/0/error.json)
Traceback (most recent call last):
  File "/home/ivieira/miniconda3/envs/lf-env/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.5.1', 'console_scripts', 'torchrun')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ivieira/miniconda3/envs/lf-env/bin/llamafactory-cli FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-01-14_13:12:38
  host      : g106.grove.adaptcentre.ie
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 149387)
  error_file: /tmp/torchelastic_97ytn305/27858b3c-92c4-4b49-9cf9-63c8e842da7e_f8057j6g/attempt_0/1/error.json
  traceback : Traceback (most recent call last):
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 919, in main
      run(args)
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 910, in run
      elastic_launch(
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
      return launch_agent(self._config, self._entrypoint, list(args))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
      result = agent.run()
               ^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
      result = f(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 696, in run
      result = self._invoke_run(role)
               ^^^^^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 849, in _invoke_run
      self._initialize_workers(self._worker_group)
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
      result = f(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 668, in _initialize_workers
      self._rendezvous(worker_group)
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
      result = f(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
      rdzv_info = spec.rdzv_handler.next_rendezvous()
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
      self._store = TCPStore(  # type: ignore[call-arg]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  RuntimeError: The server socket has failed to listen on any local network address. port: 35061, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
  
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-14_13:12:38
  host      : g106.grove.adaptcentre.ie
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 149386)
  error_file: /tmp/torchelastic_97ytn305/27858b3c-92c4-4b49-9cf9-63c8e842da7e_f8057j6g/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 919, in main
      run(args)
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/run.py", line 910, in run
      elastic_launch(
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
      return launch_agent(self._config, self._entrypoint, list(args))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
      result = agent.run()
               ^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
      result = f(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 696, in run
      result = self._invoke_run(role)
               ^^^^^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 849, in _invoke_run
      self._initialize_workers(self._worker_group)
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
      result = f(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 668, in _initialize_workers
      self._rendezvous(worker_group)
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
      result = f(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
      rdzv_info = spec.rdzv_handler.next_rendezvous()
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/ivieira/miniconda3/envs/lf-env/lib/python3.11/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
      self._store = TCPStore(  # type: ignore[call-arg]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  RuntimeError: The server socket has failed to listen on any local network address. port: 35061, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
  
============================================================
----------------------------------------
Model and checkpoint locations:
Base directory: /home/ivieira/LLaMA-Factory/
Model save path: /home/ivieira/LLaMA-Factory/saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-13-12-40
Checkpoint directory: /home/ivieira/LLaMA-Factory/saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-13-12-40/checkpoint-*
----------------------------------------
