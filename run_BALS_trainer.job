#!/bin/bash



#SBATCH -p compute
#SBATCH -J t_llam
#SBATCH --cpus-per-task=4
#SBATCH --mem=200000
#SBATCH --nodelist=g128
#SBATCH -t 8:00:00
#SBATCH --gres=gpu:a100:4

echo "=== NVIDIA Driver Version ==="
nvidia-smi
echo "=============================="

# 1) Set CUDA environment variables for version 12.1
export CUDA_HOME=/usr/local/cuda-12.1
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export PATH=$CUDA_HOME/bin:$PATH

# 2) Initialize Conda and activate environment
eval "$(/home/ivieira/mambaforge/bin/conda shell.bash hook)"
conda activate my-pip-env

# 3) Move to project directory
cd ~/chicago2/HP_FT_TM

# 4) Set GPU devices from SLURM
export CUDA_VISIBLE_DEVICES=$SLURM_STEP_GPUS

# 5) Clean previous installations
python -m pip uninstall -y torch torchvision torchaudio bitsandbytes
rm -rf ~/.local/lib/python3.8/site-packages/bitsandbytes*

# 6) Install PyTorch with CUDA 12.1 support
python -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu121

# 7) Verify PyTorch CUDA availability
echo "=== Verifying PyTorch CUDA Availability ==="
python -c "import torch; print('PyTorch version:', torch.__version__); print('PyTorch CUDA available:', torch.cuda.is_available()); print('CUDA Version:', torch.version.cuda); print('Number of GPUs:', torch.cuda.device_count()); print('GPU Names:', [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())])"
echo "=========================================="

# Exit if PyTorch CUDA is not available
python -c "import torch; assert torch.cuda.is_available(), 'PyTorch CUDA is not available'" || { echo "PyTorch CUDA is not available. Exiting."; exit 1; }

# 8) Install BitsAndBytes with CUDA 12.1 support from the multi-backend branch
echo "=== Installing BitsAndBytes from Multi-backend Branch ==="
python -m pip install --no-cache-dir --upgrade \
    "bitsandbytes@https://github.com/bitsandbytes-foundation/bitsandbytes/archive/refs/heads/main.zip"
echo "=========================================="

# 9) Verify BitsAndBytes CUDA support
echo "=== Verifying BitsAndBytes Installation ==="
python -c "
import bitsandbytes as bnb
try:
    print('BNB CUDA:', bnb.COMPILED_WITH_CUDA)
except AttributeError:
    print('BNB is not compiled with CUDA support.')
"
echo "=========================================="

# Exit if BitsAndBytes was not compiled with CUDA
python -c "
import bitsandbytes as bnb
import sys
try:
    assert bnb.COMPILED_WITH_CUDA, 'BitsAndBytes was not compiled with CUDA support.'
except AssertionError as e:
    print(e)
    sys.exit(1)
"
echo "BitsAndBytes is compiled with CUDA support."
echo "=========================================="

# 10) Install remaining packages
python -m pip install --no-cache-dir \
    ctranslate2==4.3.1 \
    "transformers>=4.38.0" \
    "trl>=0.7.6" \
    huggingface_hub \
    accelerate \
    sentencepiece \
    sacrebleu \
    pandas \
    comet \
    unbabel-comet \
    polars \
    mlflow \
    peft \
    datasets \
    safetensors

# 11) Run the trainer
python BALS_trainer.py


