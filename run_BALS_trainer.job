#!/bin/bash

#SBATCH -p compute
#SBATCH -J t_llam
#SBATCH --cpus-per-task=4
#SBATCH --mem=200000
#SBATCH --nodelist=g128
#SBATCH -t 8:00:00
#SBATCH --gres=gpu:a100:4

# Set CUDA environment variables for version 11.8 (a well-supported version)
export CUDA_HOME=/usr/local/cuda-11.8
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export PATH=$CUDA_HOME/bin:$PATH

# Initialize Conda and activate environment
eval "$(/home/ivieira/mambaforge/bin/conda shell.bash hook)"
conda activate my-pip-env

# Move to project directory
cd ~/chicago2/HP_FT_TM

# Set GPU devices from SLURM
export CUDA_VISIBLE_DEVICES=$SLURM_STEP_GPUS

# Clean previous installations
python -m pip uninstall -y bitsandbytes
rm -rf ~/.local/lib/python3.8/site-packages/bitsandbytes*

# Install packages with specific bitsandbytes version known to work with CUDA 11.8
python -m pip install --user --no-cache-dir --upgrade \
    "bitsandbytes==0.41.1" \
    torch --index-url https://download.pytorch.org/whl/cu118 \
    ctranslate2==4.3.1 \
    "transformers>=4.38.0" \
    "trl>=0.7.6" \
    huggingface_hub \
    accelerate \
    sentencepiece \
    sacrebleu \
    pandas \
    comet \
    unbabel-comet \
    polars \
    mlflow \
    peft \
    datasets \
    safetensors

# Verify bitsandbytes installation
python -c "import bitsandbytes as bnb; print('BNB CUDA:', bnb.COMPILED_WITH_CUDA)"

# Run the trainer
python BALS_trainer.py
