#!/bin/bash

#SBATCH -p compute
#SBATCH -J t_llam
#SBATCH --cpus-per-task=4
#SBATCH --mem=200000
#SBATCH --nodelist=g128
#SBATCH -t 8:00:00
#SBATCH --gres=gpu:a100:4

# 1) Set CUDA environment variables (we confirmed this works)
export CUDA_HOME=/usr/local/cuda-12.5
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export PATH=$CUDA_HOME/bin:$PATH

# 2) Initialize Conda (confirmed working path)
source /home/ivieira/mambaforge/etc/profile.d/conda.sh
eval "$(/home/ivieira/mambaforge/bin/conda shell.bash hook)"
conda activate my-pip-env

# 3) Move to project directory
cd ~/chicago2/HP_FT_TM

# 4) Set GPU devices from SLURM
export CUDA_VISIBLE_DEVICES=$SLURM_STEP_GPUS

# 5) Install dependencies in the correct order
python -m pip install --no-cache-dir \
    packaging>=20.0 \
    PyYAML>=5.4 \
    torchmetrics>=0.7.0 \
    tqdm>=4.57.0 \
    pandas>=1.4.1

# 6) Install PyTorch with CUDA 12.1 (confirmed working)
python -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu121

# 7) Install other core dependencies
python -m pip install --no-cache-dir \
    bitsandbytes \
    accelerate \
    datasets \
    tyro>=0.5.11 \
    pytorch-lightning>=2.4.0

# 8) Install remaining packages
python -m pip install --no-cache-dir \
    trl>=0.11.4 \
    unbabel-comet>=2.2.4

# 9) Run the training script
python BALS_trainer.py
