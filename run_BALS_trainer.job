#!/bin/bash

#SBATCH -p compute
#SBATCH -J t_llam
#SBATCH --cpus-per-task=4
#SBATCH --mem=200000
#SBATCH --nodelist=g128
#SBATCH -t 8:00:00
#SBATCH --gres=gpu:a100:4

# 1) Set CUDA environment variables
export CUDA_HOME=/usr/local/cuda-12.5
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export PATH=$CUDA_HOME/bin:$PATH

# 2) Initialize Conda
source /home/ivieira/mambaforge/etc/profile.d/conda.sh
eval "$(/home/ivieira/mambaforge/bin/conda shell.bash hook)"
conda activate my-pip-env

# 3) Move to project directory
cd ~/chicago2/HP_FT_TM

# 4) Set GPU devices from SLURM
export CUDA_VISIBLE_DEVICES=$SLURM_STEP_GPUS

# 5) Install PyTorch with CUDA and cuDNN via conda
conda install -y pytorch torchvision torchaudio pytorch-cuda=11.8 cudnn -c pytorch -c nvidia

# 6) Install all required packages
python -m pip install --user --no-cache-dir \
    trl peft pandas ctranslate2 transformers \
    huggingface_hub accelerate bitsandbytes \
    datasets sacrebleu unbabel-comet polars

# 7) Run the training script
python BALS_trainer.py
