[INFO|configuration_utils.py:679] 2025-01-14 17:28:01,473 >> loading configuration file config.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/config.json
[INFO|configuration_utils.py:746] 2025-01-14 17:28:01,476 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Meta-Llama-3.1-8B-Instruct",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2211] 2025-01-14 17:28:01,681 >> loading file tokenizer.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/tokenizer.json
[INFO|tokenization_utils_base.py:2211] 2025-01-14 17:28:01,681 >> loading file tokenizer.model from cache at None
[INFO|tokenization_utils_base.py:2211] 2025-01-14 17:28:01,681 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2211] 2025-01-14 17:28:01,681 >> loading file special_tokens_map.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/special_tokens_map.json
[INFO|tokenization_utils_base.py:2211] 2025-01-14 17:28:01,681 >> loading file tokenizer_config.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/tokenizer_config.json
[INFO|tokenization_utils_base.py:2475] 2025-01-14 17:28:02,101 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:679] 2025-01-14 17:28:02,992 >> loading configuration file config.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/config.json
[INFO|configuration_utils.py:746] 2025-01-14 17:28:02,994 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Meta-Llama-3.1-8B-Instruct",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2211] 2025-01-14 17:28:03,231 >> loading file tokenizer.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/tokenizer.json
[INFO|tokenization_utils_base.py:2211] 2025-01-14 17:28:03,232 >> loading file tokenizer.model from cache at None
[INFO|tokenization_utils_base.py:2211] 2025-01-14 17:28:03,232 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2211] 2025-01-14 17:28:03,232 >> loading file special_tokens_map.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/special_tokens_map.json
[INFO|tokenization_utils_base.py:2211] 2025-01-14 17:28:03,232 >> loading file tokenizer_config.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/tokenizer_config.json
[INFO|tokenization_utils_base.py:2475] 2025-01-14 17:28:03,643 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:679] 2025-01-14 17:28:04,549 >> loading configuration file config.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/config.json
[INFO|configuration_utils.py:746] 2025-01-14 17:28:04,549 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Meta-Llama-3.1-8B-Instruct",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|modeling_utils.py:3937] 2025-01-14 17:28:04,656 >> loading weights file model.safetensors from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/model.safetensors.index.json
[INFO|modeling_utils.py:1670] 2025-01-14 17:28:04,657 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1096] 2025-01-14 17:28:04,659 >> Generate config GenerationConfig {
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ]
}

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:06,  2.31s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:04<00:04,  2.11s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:06<00:02,  2.03s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:06<00:00,  1.44s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:06<00:00,  1.69s/it]
[INFO|modeling_utils.py:4800] 2025-01-14 17:28:11,592 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4808] 2025-01-14 17:28:11,592 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Meta-Llama-3.1-8B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1051] 2025-01-14 17:28:11,821 >> loading configuration file generation_config.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/generation_config.json
[INFO|configuration_utils.py:1096] 2025-01-14 17:28:11,821 >> Generate config GenerationConfig {
  "bos_token_id": 128000,
  "do_sample": true,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "temperature": 0.6,
  "top_p": 0.9
}

[INFO|trainer.py:698] 2025-01-14 17:28:12,685 >> Using auto half precision backend
[INFO|trainer.py:2313] 2025-01-14 17:28:12,896 >> ***** Running training *****
[INFO|trainer.py:2314] 2025-01-14 17:28:12,896 >>   Num examples = 23,270
[INFO|trainer.py:2315] 2025-01-14 17:28:12,896 >>   Num Epochs = 1
[INFO|trainer.py:2316] 2025-01-14 17:28:12,896 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:2319] 2025-01-14 17:28:12,896 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:2320] 2025-01-14 17:28:12,896 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:2321] 2025-01-14 17:28:12,896 >>   Total optimization steps = 728
[INFO|trainer.py:2322] 2025-01-14 17:28:12,899 >>   Number of trainable parameters = 41,943,040
[INFO|integration_utils.py:812] 2025-01-14 17:28:12,902 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: inaciovieira (inaciovieira-alpha-crc). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.2
wandb: Run data is saved locally in /home/ivieira/LLaMA-Factory/wandb/run-20250114_172813-axci8v98
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run train_2025-01-14-17-27-45
wandb: ‚≠êÔ∏è View project at https://wandb.ai/inaciovieira-alpha-crc/llamafactory
wandb: üöÄ View run at https://wandb.ai/inaciovieira-alpha-crc/llamafactory/runs/axci8v98
  0%|          | 0/728 [00:00<?, ?it/s]  0%|          | 1/728 [00:03<38:31,  3.18s/it]  0%|          | 2/728 [00:06<36:44,  3.04s/it]  0%|          | 3/728 [00:08<31:51,  2.64s/it]  1%|          | 4/728 [00:10<29:34,  2.45s/it]  1%|          | 5/728 [00:12<29:39,  2.46s/it]  1%|          | 6/728 [00:15<28:25,  2.36s/it]  1%|          | 7/728 [00:17<29:29,  2.45s/it]  1%|          | 8/728 [00:19<28:02,  2.34s/it]  1%|          | 9/728 [00:21<27:23,  2.29s/it]  1%|‚ñè         | 10/728 [00:24<27:34,  2.30s/it]                                                  1%|‚ñè         | 10/728 [00:24<27:34,  2.30s/it][INFO|trainer.py:4117] 2025-01-14 17:28:38,435 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-14 17:28:38,435 >>   Num examples = 2586
[INFO|trainer.py:4122] 2025-01-14 17:28:38,435 >>   Batch size = 16

  0%|          | 0/162 [00:00<?, ?it/s][A
  1%|          | 2/162 [00:00<00:32,  4.92it/s][A
  2%|‚ñè         | 3/162 [00:00<00:44,  3.61it/s][A
  2%|‚ñè         | 4/162 [00:01<00:51,  3.06it/s][A
  3%|‚ñé         | 5/162 [00:01<01:02,  2.53it/s][A
  4%|‚ñé         | 6/162 [00:02<01:00,  2.59it/s][A
  4%|‚ñç         | 7/162 [00:02<01:00,  2.56it/s][A
  5%|‚ñç         | 8/162 [00:03<01:06,  2.31it/s][A
  6%|‚ñå         | 9/162 [00:03<01:04,  2.37it/s][A
  6%|‚ñå         | 10/162 [00:03<01:11,  2.14it/s][A
  7%|‚ñã         | 11/162 [00:04<01:24,  1.79it/s][A
  7%|‚ñã         | 12/162 [00:05<01:15,  2.00it/s][A
  8%|‚ñä         | 13/162 [00:05<01:14,  2.00it/s][A
  9%|‚ñä         | 14/162 [00:06<01:09,  2.11it/s][A
  9%|‚ñâ         | 15/162 [00:06<01:05,  2.24it/s][A
 10%|‚ñâ         | 16/162 [00:06<01:02,  2.34it/s][A
 10%|‚ñà         | 17/162 [00:07<01:03,  2.29it/s][A
 11%|‚ñà         | 18/162 [00:07<01:08,  2.11it/s][A
 12%|‚ñà‚ñè        | 19/162 [00:08<01:05,  2.18it/s][A
 12%|‚ñà‚ñè        | 20/162 [00:08<01:10,  2.02it/s][A
 13%|‚ñà‚ñé        | 21/162 [00:09<01:06,  2.13it/s][A
 14%|‚ñà‚ñé        | 22/162 [00:09<01:01,  2.28it/s][A
 14%|‚ñà‚ñç        | 23/162 [00:10<01:10,  1.96it/s][A
 15%|‚ñà‚ñç        | 24/162 [00:10<01:06,  2.08it/s][A
 15%|‚ñà‚ñå        | 25/162 [00:11<01:03,  2.16it/s][A
 16%|‚ñà‚ñå        | 26/162 [00:11<01:00,  2.23it/s][A
 17%|‚ñà‚ñã        | 27/162 [00:12<01:33,  1.44it/s][A
 17%|‚ñà‚ñã        | 28/162 [00:13<01:21,  1.64it/s][A
 18%|‚ñà‚ñä        | 29/162 [00:13<01:12,  1.85it/s][A
 19%|‚ñà‚ñä        | 30/162 [00:14<01:08,  1.92it/s][A
 19%|‚ñà‚ñâ        | 31/162 [00:14<01:03,  2.05it/s][A
 20%|‚ñà‚ñâ        | 32/162 [00:14<00:59,  2.19it/s][A
 20%|‚ñà‚ñà        | 33/162 [00:15<00:56,  2.28it/s][A
 21%|‚ñà‚ñà        | 34/162 [00:15<01:03,  2.01it/s][A
 22%|‚ñà‚ñà‚ñè       | 35/162 [00:16<00:59,  2.13it/s][A
 22%|‚ñà‚ñà‚ñè       | 36/162 [00:17<01:32,  1.36it/s][A
 23%|‚ñà‚ñà‚ñé       | 37/162 [00:18<01:19,  1.57it/s][A
 23%|‚ñà‚ñà‚ñé       | 38/162 [00:18<01:11,  1.74it/s][A
 24%|‚ñà‚ñà‚ñç       | 39/162 [00:19<01:11,  1.71it/s][A
 25%|‚ñà‚ñà‚ñç       | 40/162 [00:19<01:02,  1.95it/s][A
 25%|‚ñà‚ñà‚ñå       | 41/162 [00:19<01:02,  1.94it/s][A
 26%|‚ñà‚ñà‚ñå       | 42/162 [00:20<00:55,  2.15it/s][A
 27%|‚ñà‚ñà‚ñã       | 43/162 [00:20<00:53,  2.23it/s][A
 27%|‚ñà‚ñà‚ñã       | 44/162 [00:21<00:58,  2.01it/s][A
 28%|‚ñà‚ñà‚ñä       | 45/162 [00:21<00:54,  2.14it/s][A
 28%|‚ñà‚ñà‚ñä       | 46/162 [00:22<00:51,  2.24it/s][A
 29%|‚ñà‚ñà‚ñâ       | 47/162 [00:22<00:51,  2.22it/s][A
 30%|‚ñà‚ñà‚ñâ       | 48/162 [00:23<00:51,  2.20it/s][A
 30%|‚ñà‚ñà‚ñà       | 49/162 [00:23<00:48,  2.32it/s][A
 31%|‚ñà‚ñà‚ñà       | 50/162 [00:23<00:49,  2.27it/s][A
 31%|‚ñà‚ñà‚ñà‚ñè      | 51/162 [00:24<00:46,  2.36it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 52/162 [00:24<00:46,  2.39it/s][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 53/162 [00:25<00:43,  2.48it/s][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 54/162 [00:25<00:43,  2.49it/s][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 55/162 [00:25<00:41,  2.59it/s][A
 35%|‚ñà‚ñà‚ñà‚ñç      | 56/162 [00:26<00:40,  2.60it/s][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 57/162 [00:26<00:42,  2.45it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 58/162 [00:27<00:42,  2.45it/s][A
 36%|‚ñà‚ñà‚ñà‚ñã      | 59/162 [00:27<00:44,  2.30it/s][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 60/162 [00:27<00:44,  2.31it/s][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 61/162 [00:28<00:42,  2.35it/s][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 62/162 [00:28<00:41,  2.40it/s][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 63/162 [00:29<00:40,  2.43it/s][A
 40%|‚ñà‚ñà‚ñà‚ñâ      | 64/162 [00:29<00:42,  2.33it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 65/162 [00:30<00:41,  2.34it/s][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 66/162 [00:30<00:39,  2.41it/s][A
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 67/162 [00:30<00:40,  2.33it/s][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 68/162 [00:31<00:38,  2.47it/s][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 69/162 [00:31<00:39,  2.35it/s][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 70/162 [00:32<00:44,  2.08it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 71/162 [00:32<00:41,  2.21it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 72/162 [00:33<00:50,  1.77it/s][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 73/162 [00:33<00:45,  1.95it/s][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 74/162 [00:34<00:42,  2.07it/s][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 75/162 [00:34<00:38,  2.23it/s][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 76/162 [00:35<00:40,  2.12it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 77/162 [00:35<00:42,  1.99it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 78/162 [00:39<01:13,  1.15it/s][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 79/162 [00:40<01:57,  1.42s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 80/162 [00:40<01:33,  1.13s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 81/162 [00:41<01:14,  1.09it/s][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 82/162 [00:41<01:01,  1.31it/s][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 83/162 [00:41<00:50,  1.55it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 84/162 [00:42<00:44,  1.77it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 85/162 [00:42<00:38,  2.00it/s][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 86/162 [00:56<00:36,  2.07it/s][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 87/162 [00:56<05:37,  4.50s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 88/162 [00:57<04:02,  3.27s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 89/162 [00:57<02:55,  2.40s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 90/162 [00:58<02:10,  1.82s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 91/162 [00:58<01:39,  1.39s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 92/162 [00:58<01:16,  1.09s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 93/162 [00:59<01:00,  1.15it/s][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 94/162 [00:59<00:49,  1.37it/s][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 95/162 [01:00<00:41,  1.61it/s][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 96/162 [01:00<00:37,  1.78it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 97/162 [01:00<00:33,  1.93it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 98/162 [01:01<00:30,  2.09it/s][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 99/162 [01:12<00:27,  2.27it/s][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 100/162 [01:12<03:40,  3.56s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 101/162 [01:12<02:39,  2.61s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 102/162 [01:13<01:56,  1.94s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 103/162 [01:13<01:28,  1.51s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 104/162 [01:14<01:07,  1.17s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 105/162 [01:14<00:53,  1.06it/s][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 106/162 [01:14<00:42,  1.31it/s][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 107/162 [01:15<00:35,  1.55it/s][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 108/162 [01:15<00:30,  1.77it/s][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 109/162 [01:16<00:27,  1.94it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 110/162 [01:16<00:24,  2.11it/s][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 111/162 [01:16<00:22,  2.26it/s][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 112/162 [01:28<00:21,  2.29it/s][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 113/162 [01:28<03:05,  3.79s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 114/162 [01:29<02:12,  2.76s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 115/162 [01:29<01:36,  2.05s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 116/162 [01:29<01:10,  1.54s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 117/162 [01:30<00:53,  1.20s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 118/162 [01:30<00:42,  1.04it/s][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 119/162 [01:31<00:34,  1.23it/s][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 120/162 [01:31<00:28,  1.46it/s][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 121/162 [01:32<00:25,  1.62it/s][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 122/162 [01:32<00:22,  1.79it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 123/162 [01:32<00:19,  1.97it/s][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 124/162 [01:33<00:18,  2.09it/s][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 125/162 [01:45<00:17,  2.17it/s][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 126/162 [01:45<02:21,  3.92s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 127/162 [01:46<01:39,  2.86s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 128/162 [01:46<01:12,  2.13s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 129/162 [01:46<00:53,  1.61s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 130/162 [01:47<00:39,  1.24s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 131/162 [01:47<00:31,  1.01s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 132/162 [01:48<00:24,  1.20it/s][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 133/162 [01:48<00:20,  1.43it/s][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 134/162 [01:48<00:16,  1.65it/s][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 135/162 [01:49<00:14,  1.88it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 136/162 [01:49<00:13,  1.98it/s][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 137/162 [01:50<00:12,  2.00it/s][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 138/162 [02:01<00:11,  2.15it/s][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 139/162 [02:01<01:22,  3.60s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 140/162 [02:01<00:57,  2.63s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 141/162 [02:02<00:41,  1.96s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 142/162 [02:02<00:29,  1.49s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 143/162 [02:03<00:22,  1.17s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 144/162 [02:03<00:17,  1.04it/s][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 145/162 [02:03<00:13,  1.27it/s][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 146/162 [02:04<00:10,  1.51it/s][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 147/162 [02:05<00:09,  1.51it/s][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 148/162 [02:05<00:08,  1.71it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 149/162 [02:05<00:06,  1.92it/s][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 150/162 [02:17<00:05,  2.06it/s][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 151/162 [02:17<00:42,  3.87s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 152/162 [02:18<00:28,  2.86s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 153/162 [02:18<00:19,  2.12s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 154/162 [02:19<00:12,  1.60s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 155/162 [02:19<00:08,  1.25s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 156/162 [02:20<00:05,  1.02it/s][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 157/162 [02:20<00:04,  1.15it/s][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 158/162 [02:20<00:02,  1.40it/s][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 159/162 [02:21<00:01,  1.61it/s][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 160/162 [02:21<00:01,  1.81it/s][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 161/162 [02:22<00:00,  1.92it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [02:22<00:00,  2.25it/s][A                                                
                                                 [A  1%|‚ñè         | 10/728 [02:47<27:34,  2.30s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [02:22<00:00,  2.25it/s][A
                                                 [A[INFO|trainer.py:3801] 2025-01-14 17:31:01,357 >> Saving model checkpoint to saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-17-27-45/checkpoint-10
[INFO|configuration_utils.py:679] 2025-01-14 17:31:01,995 >> loading configuration file config.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/config.json
[INFO|configuration_utils.py:746] 2025-01-14 17:31:07,989 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2646] 2025-01-14 17:31:08,225 >> tokenizer config file saved in saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-17-27-45/checkpoint-10/tokenizer_config.json
[INFO|tokenization_utils_base.py:2655] 2025-01-14 17:31:08,226 >> Special tokens file saved in saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-17-27-45/checkpoint-10/special_tokens_map.json
  2%|‚ñè         | 11/728 [02:57<9:38:28, 48.41s/it]  2%|‚ñè         | 12/728 [02:59<6:48:54, 34.27s/it]  2%|‚ñè         | 13/728 [03:02<4:57:28, 24.96s/it]  2%|‚ñè         | 14/728 [03:04<3:34:50, 18.05s/it]  2%|‚ñè         | 15/728 [03:10<2:50:05, 14.31s/it]  2%|‚ñè         | 16/728 [03:13<2:08:37, 10.84s/it]  2%|‚ñè         | 17/728 [03:16<1:42:31,  8.65s/it]  2%|‚ñè         | 18/728 [03:19<1:19:40,  6.73s/it]  3%|‚ñé         | 19/728 [03:21<1:03:42,  5.39s/it]  3%|‚ñé         | 20/728 [03:23<52:49,  4.48s/it]                                                    3%|‚ñé         | 20/728 [03:23<52:49,  4.48s/it][INFO|trainer.py:4117] 2025-01-14 17:31:37,801 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-14 17:31:37,801 >>   Num examples = 2586
[INFO|trainer.py:4122] 2025-01-14 17:31:37,801 >>   Batch size = 16

  0%|          | 0/162 [00:00<?, ?it/s][A
  1%|          | 2/162 [00:00<00:32,  4.91it/s][A
  2%|‚ñè         | 3/162 [00:00<00:44,  3.59it/s][A
  2%|‚ñè         | 4/162 [00:01<00:51,  3.06it/s][A
  3%|‚ñé         | 5/162 [00:01<01:02,  2.52it/s][A
  4%|‚ñé         | 6/162 [00:02<01:00,  2.59it/s][A
  4%|‚ñç         | 7/162 [00:02<01:00,  2.56it/s][A
  5%|‚ñç         | 8/162 [00:03<01:06,  2.31it/s][A
  6%|‚ñå         | 9/162 [00:03<01:04,  2.37it/s][A
  6%|‚ñå         | 10/162 [00:03<01:11,  2.13it/s][A
  7%|‚ñã         | 11/162 [00:04<01:24,  1.79it/s][A
  7%|‚ñã         | 12/162 [00:05<01:15,  2.00it/s][A
  8%|‚ñä         | 13/162 [00:05<01:14,  2.00it/s][A
  9%|‚ñä         | 14/162 [00:06<01:10,  2.11it/s][A
  9%|‚ñâ         | 15/162 [00:06<01:05,  2.24it/s][A
 10%|‚ñâ         | 16/162 [00:06<01:02,  2.34it/s][A
 10%|‚ñà         | 17/162 [00:07<01:03,  2.29it/s][A
 11%|‚ñà         | 18/162 [00:07<01:08,  2.11it/s][A
 12%|‚ñà‚ñè        | 19/162 [00:08<01:05,  2.18it/s][A
 12%|‚ñà‚ñè        | 20/162 [00:08<01:10,  2.02it/s][A
 13%|‚ñà‚ñé        | 21/162 [00:09<01:06,  2.13it/s][A
 14%|‚ñà‚ñé        | 22/162 [00:09<01:01,  2.28it/s][A
 14%|‚ñà‚ñç        | 23/162 [00:10<01:10,  1.96it/s][A
 15%|‚ñà‚ñç        | 24/162 [00:10<01:06,  2.08it/s][A
 15%|‚ñà‚ñå        | 25/162 [00:11<01:03,  2.16it/s][A
 16%|‚ñà‚ñå        | 26/162 [00:11<01:00,  2.23it/s][A
 17%|‚ñà‚ñã        | 27/162 [00:12<01:33,  1.44it/s][A
 17%|‚ñà‚ñã        | 28/162 [00:13<01:21,  1.64it/s][A
 18%|‚ñà‚ñä        | 29/162 [00:13<01:12,  1.85it/s][A
 19%|‚ñà‚ñä        | 30/162 [00:14<01:08,  1.92it/s][A
 19%|‚ñà‚ñâ        | 31/162 [00:14<01:03,  2.05it/s][A
 20%|‚ñà‚ñâ        | 32/162 [00:14<00:59,  2.19it/s][A
 20%|‚ñà‚ñà        | 33/162 [00:15<00:56,  2.28it/s][A
 21%|‚ñà‚ñà        | 34/162 [00:15<01:03,  2.01it/s][A
 22%|‚ñà‚ñà‚ñè       | 35/162 [00:16<00:59,  2.13it/s][A
 22%|‚ñà‚ñà‚ñè       | 36/162 [00:17<01:32,  1.36it/s][A
 23%|‚ñà‚ñà‚ñé       | 37/162 [00:18<01:19,  1.57it/s][A
 23%|‚ñà‚ñà‚ñé       | 38/162 [00:18<01:11,  1.74it/s][A
 24%|‚ñà‚ñà‚ñç       | 39/162 [00:19<01:11,  1.71it/s][A
 25%|‚ñà‚ñà‚ñç       | 40/162 [00:19<01:02,  1.95it/s][A
 25%|‚ñà‚ñà‚ñå       | 41/162 [00:19<01:02,  1.94it/s][A
 26%|‚ñà‚ñà‚ñå       | 42/162 [00:20<00:55,  2.16it/s][A
 27%|‚ñà‚ñà‚ñã       | 43/162 [00:20<00:53,  2.23it/s][A
 27%|‚ñà‚ñà‚ñã       | 44/162 [00:21<00:58,  2.01it/s][A
 28%|‚ñà‚ñà‚ñä       | 45/162 [00:21<00:54,  2.14it/s][A
 28%|‚ñà‚ñà‚ñä       | 46/162 [00:22<00:51,  2.24it/s][A
 29%|‚ñà‚ñà‚ñâ       | 47/162 [00:22<00:51,  2.22it/s][A
 30%|‚ñà‚ñà‚ñâ       | 48/162 [00:23<00:51,  2.21it/s][A
 30%|‚ñà‚ñà‚ñà       | 49/162 [00:23<00:48,  2.31it/s][A
 31%|‚ñà‚ñà‚ñà       | 50/162 [00:23<00:49,  2.27it/s][A
 31%|‚ñà‚ñà‚ñà‚ñè      | 51/162 [00:24<00:46,  2.36it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 52/162 [00:24<00:46,  2.39it/s][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 53/162 [00:25<00:43,  2.48it/s][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 54/162 [00:25<00:43,  2.49it/s][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 55/162 [00:25<00:41,  2.59it/s][A
 35%|‚ñà‚ñà‚ñà‚ñç      | 56/162 [00:26<00:40,  2.60it/s][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 57/162 [00:26<00:42,  2.45it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 58/162 [00:27<00:42,  2.47it/s][A
 36%|‚ñà‚ñà‚ñà‚ñã      | 59/162 [00:27<00:44,  2.31it/s][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 60/162 [00:27<00:43,  2.32it/s][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 61/162 [00:28<00:42,  2.36it/s][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 62/162 [00:29<00:51,  1.93it/s][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 63/162 [00:29<00:47,  2.08it/s][A
 40%|‚ñà‚ñà‚ñà‚ñâ      | 64/162 [00:29<00:46,  2.09it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 65/162 [00:30<00:44,  2.17it/s][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 66/162 [00:30<00:42,  2.28it/s][A
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 67/162 [00:31<00:42,  2.25it/s][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 68/162 [00:31<00:39,  2.40it/s][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 69/162 [00:32<00:40,  2.31it/s][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 70/162 [00:32<00:39,  2.35it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 71/162 [00:32<00:37,  2.42it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 72/162 [00:33<00:48,  1.86it/s][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 73/162 [00:34<00:44,  2.02it/s][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 74/162 [00:34<00:41,  2.13it/s][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 75/162 [00:34<00:38,  2.28it/s][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 76/162 [00:35<00:39,  2.15it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 77/162 [00:35<00:42,  2.01it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 78/162 [00:37<01:13,  1.15it/s][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 79/162 [00:38<00:59,  1.39it/s][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 80/162 [00:38<00:52,  1.55it/s][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 81/162 [00:38<00:46,  1.73it/s][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 82/162 [00:39<00:41,  1.91it/s][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 83/162 [00:39<00:37,  2.10it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 84/162 [00:40<00:35,  2.23it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 85/162 [00:40<00:32,  2.38it/s][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 86/162 [00:40<00:32,  2.34it/s][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 87/162 [00:41<00:39,  1.89it/s][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 88/162 [00:42<00:36,  2.01it/s][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 89/162 [00:42<00:33,  2.19it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 90/162 [00:42<00:32,  2.18it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 91/162 [00:43<00:31,  2.26it/s][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 92/162 [00:43<00:29,  2.35it/s][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 93/162 [00:44<00:28,  2.46it/s][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 94/162 [00:44<00:27,  2.47it/s][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 95/162 [00:44<00:26,  2.55it/s][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 96/162 [00:45<00:26,  2.49it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 97/162 [00:45<00:26,  2.45it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 98/162 [00:46<00:25,  2.50it/s][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 99/162 [00:46<00:24,  2.60it/s][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 100/162 [00:46<00:25,  2.48it/s][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 101/162 [00:47<00:24,  2.49it/s][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 102/162 [00:47<00:23,  2.56it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 103/162 [00:48<00:25,  2.36it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 104/162 [00:48<00:23,  2.43it/s][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 105/162 [00:48<00:23,  2.41it/s][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 106/162 [00:49<00:22,  2.53it/s][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 107/162 [00:49<00:21,  2.58it/s][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 108/162 [00:50<00:20,  2.59it/s][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 109/162 [00:50<00:20,  2.57it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 110/162 [00:50<00:20,  2.58it/s][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 111/162 [00:51<00:19,  2.62it/s][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 112/162 [00:51<00:19,  2.54it/s][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 113/162 [00:51<00:18,  2.59it/s][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 114/162 [00:52<00:18,  2.67it/s][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 115/162 [00:52<00:17,  2.62it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 116/162 [00:53<00:16,  2.71it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 117/162 [00:53<00:17,  2.62it/s][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 118/162 [00:53<00:17,  2.54it/s][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 119/162 [00:54<00:17,  2.41it/s][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 120/162 [00:54<00:16,  2.47it/s][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 121/162 [00:55<00:17,  2.37it/s][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 122/162 [00:55<00:16,  2.37it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 123/162 [00:55<00:16,  2.41it/s][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 124/162 [00:56<00:15,  2.42it/s][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 125/162 [00:56<00:15,  2.40it/s][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 126/162 [00:57<00:14,  2.49it/s][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 127/162 [00:57<00:13,  2.56it/s][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 128/162 [00:57<00:13,  2.50it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 129/162 [00:58<00:13,  2.45it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 130/162 [00:58<00:12,  2.56it/s][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 131/162 [00:59<00:13,  2.36it/s][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 132/162 [00:59<00:12,  2.38it/s][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 133/162 [01:00<00:11,  2.42it/s][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 134/162 [01:00<00:11,  2.47it/s][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 135/162 [01:00<00:10,  2.54it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 136/162 [01:01<00:10,  2.45it/s][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 137/162 [01:01<00:10,  2.31it/s][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 138/162 [01:02<00:10,  2.40it/s][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 139/162 [01:02<00:09,  2.49it/s][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 140/162 [01:02<00:08,  2.59it/s][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 141/162 [01:03<00:08,  2.54it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 142/162 [01:03<00:07,  2.51it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 143/162 [01:04<00:07,  2.46it/s][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 144/162 [01:04<00:07,  2.37it/s][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 145/162 [01:04<00:07,  2.41it/s][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 146/162 [01:05<00:06,  2.50it/s][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 147/162 [01:05<00:07,  2.08it/s][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 148/162 [01:06<00:06,  2.18it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 149/162 [01:06<00:05,  2.32it/s][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 150/162 [01:07<00:05,  2.35it/s][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 151/162 [01:07<00:04,  2.40it/s][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 152/162 [01:08<00:04,  2.26it/s][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 153/162 [01:08<00:03,  2.33it/s][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 154/162 [01:08<00:03,  2.41it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 155/162 [01:09<00:02,  2.36it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 156/162 [01:09<00:02,  2.49it/s][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 157/162 [01:10<00:02,  2.17it/s][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 158/162 [01:10<00:01,  2.31it/s][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 159/162 [01:10<00:01,  2.37it/s][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 160/162 [01:11<00:00,  2.41it/s][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 161/162 [01:11<00:00,  2.36it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [01:12<00:00,  2.65it/s][A                                                
                                                 [A  3%|‚ñé         | 20/728 [04:36<52:49,  4.48s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [01:12<00:00,  2.65it/s][A
                                                 [A[INFO|trainer.py:3801] 2025-01-14 17:32:50,334 >> Saving model checkpoint to saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-17-27-45/checkpoint-20
[INFO|configuration_utils.py:679] 2025-01-14 17:32:50,838 >> loading configuration file config.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/config.json
[INFO|configuration_utils.py:746] 2025-01-14 17:32:50,839 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2646] 2025-01-14 17:32:51,036 >> tokenizer config file saved in saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-17-27-45/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2655] 2025-01-14 17:32:51,036 >> Special tokens file saved in saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-17-27-45/checkpoint-20/special_tokens_map.json
  3%|‚ñé         | 21/728 [04:39<5:04:52, 25.87s/it]  3%|‚ñé         | 22/728 [04:41<3:41:49, 18.85s/it]  3%|‚ñé         | 23/728 [04:49<3:02:55, 15.57s/it]  3%|‚ñé         | 24/728 [04:53<2:22:21, 12.13s/it]  3%|‚ñé         | 25/728 [04:56<1:47:09,  9.15s/it]  4%|‚ñé         | 26/728 [04:58<1:22:52,  7.08s/it]  4%|‚ñé         | 27/728 [05:00<1:05:54,  5.64s/it]  4%|‚ñç         | 28/728 [05:02<53:42,  4.60s/it]    4%|‚ñç         | 29/728 [05:05<46:32,  4.00s/it]  4%|‚ñç         | 30/728 [05:07<40:45,  3.50s/it]                                                  4%|‚ñç         | 30/728 [05:07<40:45,  3.50s/it][INFO|trainer.py:4117] 2025-01-14 17:33:21,939 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-14 17:33:21,945 >>   Num examples = 2586
[INFO|trainer.py:4122] 2025-01-14 17:33:21,955 >>   Batch size = 16

  0%|          | 0/162 [00:00<?, ?it/s][A
  1%|          | 2/162 [00:00<00:33,  4.80it/s][A
  2%|‚ñè         | 3/162 [00:00<00:46,  3.46it/s][A
  2%|‚ñè         | 4/162 [00:01<00:54,  2.91it/s][A
  3%|‚ñé         | 5/162 [00:01<01:05,  2.41it/s][A
  4%|‚ñé         | 6/162 [00:02<01:03,  2.46it/s][A
  4%|‚ñç         | 7/162 [00:02<01:03,  2.43it/s][A
  5%|‚ñç         | 8/162 [00:03<01:09,  2.20it/s][A
  6%|‚ñå         | 9/162 [00:03<01:07,  2.26it/s][A
  6%|‚ñå         | 10/162 [00:04<01:14,  2.04it/s][A
  7%|‚ñã         | 11/162 [00:05<01:29,  1.69it/s][A
  7%|‚ñã         | 12/162 [00:05<01:19,  1.89it/s][A
  8%|‚ñä         | 13/162 [00:05<01:18,  1.90it/s][A
  9%|‚ñä         | 14/162 [00:06<01:13,  2.00it/s][A
  9%|‚ñâ         | 15/162 [00:06<01:09,  2.13it/s][A
 10%|‚ñâ         | 16/162 [00:07<01:05,  2.22it/s][A
 10%|‚ñà         | 17/162 [00:07<01:06,  2.17it/s][A
 11%|‚ñà         | 18/162 [00:08<01:11,  2.02it/s][A
 12%|‚ñà‚ñè        | 19/162 [00:08<01:08,  2.08it/s][A
 12%|‚ñà‚ñè        | 20/162 [00:09<01:13,  1.93it/s][A
 13%|‚ñà‚ñé        | 21/162 [00:09<01:09,  2.03it/s][A
 14%|‚ñà‚ñé        | 22/162 [00:10<01:04,  2.17it/s][A
 14%|‚ñà‚ñç        | 23/162 [00:10<01:14,  1.88it/s][A
 15%|‚ñà‚ñç        | 24/162 [00:11<01:09,  1.99it/s][A
 15%|‚ñà‚ñå        | 25/162 [00:11<01:06,  2.06it/s][A
 16%|‚ñà‚ñå        | 26/162 [00:12<01:03,  2.13it/s][A
 17%|‚ñà‚ñã        | 27/162 [00:13<01:36,  1.39it/s][A
 17%|‚ñà‚ñã        | 28/162 [00:13<01:24,  1.58it/s][A
 18%|‚ñà‚ñä        | 29/162 [00:14<01:14,  1.78it/s][A
 19%|‚ñà‚ñä        | 30/162 [00:14<01:11,  1.84it/s][A
 19%|‚ñà‚ñâ        | 31/162 [00:15<01:06,  1.96it/s][A
 20%|‚ñà‚ñâ        | 32/162 [00:15<01:02,  2.09it/s][A
 20%|‚ñà‚ñà        | 33/162 [00:15<00:59,  2.17it/s][A
 21%|‚ñà‚ñà        | 34/162 [00:16<01:06,  1.92it/s][A
 22%|‚ñà‚ñà‚ñè       | 35/162 [00:17<01:02,  2.04it/s][A
 22%|‚ñà‚ñà‚ñè       | 36/162 [00:18<01:35,  1.32it/s][A
 23%|‚ñà‚ñà‚ñé       | 37/162 [00:18<01:22,  1.52it/s][A
 23%|‚ñà‚ñà‚ñé       | 38/162 [00:19<01:13,  1.68it/s][A
 24%|‚ñà‚ñà‚ñç       | 39/162 [00:19<01:14,  1.65it/s][A
 25%|‚ñà‚ñà‚ñç       | 40/162 [00:20<01:04,  1.88it/s][A
 25%|‚ñà‚ñà‚ñå       | 41/162 [00:20<01:05,  1.86it/s][A
 26%|‚ñà‚ñà‚ñå       | 42/162 [00:21<00:58,  2.06it/s][A
 27%|‚ñà‚ñà‚ñã       | 43/162 [00:21<00:55,  2.13it/s][A
 27%|‚ñà‚ñà‚ñã       | 44/162 [00:22<01:00,  1.94it/s][A
 28%|‚ñà‚ñà‚ñä       | 45/162 [00:22<00:57,  2.05it/s][A
 28%|‚ñà‚ñà‚ñä       | 46/162 [00:23<00:54,  2.14it/s][A
 29%|‚ñà‚ñà‚ñâ       | 47/162 [00:23<00:54,  2.12it/s][A
 30%|‚ñà‚ñà‚ñâ       | 48/162 [00:24<00:54,  2.11it/s][A
 30%|‚ñà‚ñà‚ñà       | 49/162 [00:24<00:51,  2.20it/s][A
 31%|‚ñà‚ñà‚ñà       | 50/162 [00:24<00:51,  2.16it/s][A
 31%|‚ñà‚ñà‚ñà‚ñè      | 51/162 [00:25<00:49,  2.25it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 52/162 [00:25<00:48,  2.27it/s][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 53/162 [00:26<00:46,  2.35it/s][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 54/162 [00:26<00:45,  2.36it/s][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 55/162 [00:26<00:43,  2.46it/s][A
 35%|‚ñà‚ñà‚ñà‚ñç      | 56/162 [00:27<00:43,  2.46it/s][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 57/162 [00:27<00:45,  2.32it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 58/162 [00:28<00:44,  2.33it/s][A
 36%|‚ñà‚ñà‚ñà‚ñã      | 59/162 [00:28<00:47,  2.17it/s][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 60/162 [00:29<00:46,  2.18it/s][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 61/162 [00:29<00:45,  2.20it/s][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 62/162 [00:30<00:44,  2.25it/s][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 63/162 [00:30<00:43,  2.27it/s][A
 40%|‚ñà‚ñà‚ñà‚ñâ      | 64/162 [00:31<00:44,  2.19it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 65/162 [00:31<00:44,  2.19it/s][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 66/162 [00:31<00:42,  2.25it/s][A
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 67/162 [00:32<00:43,  2.19it/s][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 68/162 [00:32<00:41,  2.28it/s][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 69/162 [00:33<00:42,  2.19it/s][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 70/162 [00:33<00:41,  2.21it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 71/162 [00:34<00:39,  2.28it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 72/162 [00:35<00:50,  1.77it/s][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 73/162 [00:35<00:46,  1.91it/s][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 74/162 [00:35<00:43,  2.00it/s][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 75/162 [00:36<00:40,  2.13it/s][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 76/162 [00:36<00:42,  2.02it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 77/162 [00:37<00:44,  1.90it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 78/162 [00:39<01:15,  1.11it/s][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 79/162 [00:39<01:04,  1.28it/s][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 80/162 [00:40<00:57,  1.43it/s][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 81/162 [00:40<00:52,  1.55it/s][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 82/162 [00:41<00:46,  1.72it/s][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 83/162 [00:41<00:42,  1.86it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 84/162 [00:42<00:39,  2.00it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 85/162 [00:42<00:35,  2.15it/s][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 86/162 [00:42<00:35,  2.13it/s][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 87/162 [00:43<00:42,  1.77it/s][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 88/162 [00:44<00:39,  1.86it/s][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 89/162 [00:44<00:36,  1.98it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 90/162 [00:45<00:36,  1.99it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 91/162 [00:45<00:34,  2.07it/s][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 92/162 [00:45<00:32,  2.16it/s][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 93/162 [00:46<00:30,  2.27it/s][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 94/162 [00:46<00:29,  2.29it/s][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 95/162 [00:47<00:28,  2.35it/s][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 96/162 [00:47<00:28,  2.31it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 97/162 [00:48<00:28,  2.28it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 98/162 [00:48<00:27,  2.29it/s][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 99/162 [00:48<00:26,  2.37it/s][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 100/162 [00:50<00:47,  1.30it/s][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 101/162 [00:50<00:40,  1.51it/s][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 102/162 [00:51<00:34,  1.71it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 103/162 [00:51<00:33,  1.77it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 104/162 [00:52<00:30,  1.92it/s][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 105/162 [00:52<00:28,  2.01it/s][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 106/162 [00:53<00:25,  2.17it/s][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 107/162 [00:53<00:24,  2.28it/s][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 108/162 [00:53<00:23,  2.33it/s][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 109/162 [00:54<00:22,  2.34it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 110/162 [00:54<00:21,  2.38it/s][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 111/162 [00:55<00:21,  2.42it/s][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 112/162 [00:55<00:21,  2.35it/s][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 113/162 [00:55<00:20,  2.41it/s][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 114/162 [00:56<00:19,  2.48it/s][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 115/162 [00:56<00:19,  2.45it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 116/162 [00:57<00:18,  2.52it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 117/162 [00:57<00:18,  2.44it/s][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 118/162 [00:57<00:18,  2.37it/s][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 119/162 [00:58<00:18,  2.27it/s][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 120/162 [00:58<00:18,  2.32it/s][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 121/162 [00:59<00:18,  2.23it/s][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 122/162 [00:59<00:17,  2.24it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 123/162 [01:00<00:17,  2.27it/s][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 124/162 [01:00<00:16,  2.29it/s][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 125/162 [01:01<00:16,  2.26it/s][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 126/162 [01:01<00:15,  2.34it/s][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 127/162 [01:01<00:14,  2.39it/s][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 128/162 [01:02<00:14,  2.34it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 129/162 [01:02<00:14,  2.31it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 130/162 [01:03<00:13,  2.40it/s][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 131/162 [01:03<00:13,  2.23it/s][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 132/162 [01:04<00:13,  2.24it/s][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 133/162 [01:04<00:12,  2.27it/s][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 134/162 [01:04<00:12,  2.33it/s][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 135/162 [01:05<00:11,  2.39it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 136/162 [01:05<00:11,  2.29it/s][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 137/162 [01:06<00:11,  2.17it/s][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 138/162 [01:06<00:10,  2.26it/s][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 139/162 [01:07<00:09,  2.33it/s][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 140/162 [01:07<00:09,  2.42it/s][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 141/162 [01:07<00:08,  2.39it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 142/162 [01:08<00:08,  2.36it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 143/162 [01:08<00:08,  2.33it/s][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 144/162 [01:09<00:08,  2.24it/s][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 145/162 [01:09<00:07,  2.28it/s][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 146/162 [01:10<00:06,  2.35it/s][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 147/162 [01:10<00:07,  1.98it/s][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 148/162 [01:11<00:06,  2.06it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 149/162 [01:11<00:05,  2.19it/s][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 150/162 [01:12<00:05,  2.22it/s][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 151/162 [01:12<00:04,  2.26it/s][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 152/162 [01:13<00:04,  2.14it/s][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 153/162 [01:13<00:04,  2.20it/s][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 154/162 [01:13<00:03,  2.27it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 155/162 [01:14<00:03,  2.22it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 156/162 [01:14<00:02,  2.34it/s][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 157/162 [01:15<00:02,  2.05it/s][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 158/162 [01:15<00:01,  2.19it/s][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 159/162 [01:16<00:01,  2.23it/s][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 160/162 [01:16<00:00,  2.27it/s][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 161/162 [01:17<00:00,  2.23it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [01:17<00:00,  2.47it/s][A                                                
                                                 [A  4%|‚ñç         | 30/728 [06:25<40:45,  3.50s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [01:17<00:00,  2.47it/s][A
                                                 [A[INFO|trainer.py:3801] 2025-01-14 17:34:39,945 >> Saving model checkpoint to saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-17-27-45/checkpoint-30
[INFO|configuration_utils.py:679] 2025-01-14 17:34:40,455 >> loading configuration file config.json from cache at /home/ivieira/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/config.json
[INFO|configuration_utils.py:746] 2025-01-14 17:34:40,469 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2646] 2025-01-14 17:34:40,709 >> tokenizer config file saved in saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-17-27-45/checkpoint-30/tokenizer_config.json
[INFO|tokenization_utils_base.py:2655] 2025-01-14 17:34:40,719 >> Special tokens file saved in saves/Llama-3.1-8B-Instruct/lora/train_2025-01-14-17-27-45/checkpoint-30/special_tokens_map.json
  4%|‚ñç         | 31/728 [06:35<5:33:28, 28.71s/it]  4%|‚ñç         | 32/728 [06:37<4:01:43, 20.84s/it]  5%|‚ñç         | 33/728 [06:40<2:57:08, 15.29s/it]  5%|‚ñç         | 34/728 [06:43<2:14:05, 11.59s/it]  5%|‚ñç         | 35/728 [06:45<1:40:28,  8.70s/it]  5%|‚ñç         | 36/728 [06:47<1:18:07,  6.77s/it]slurmstepd-g129: error: *** JOB 223257 ON g129 CANCELLED AT 2025-01-14T17:35:05 ***
