#!/bin/bash
#SBATCH -p compute
#SBATCH -J llama_factory
#SBATCH --cpus-per-task=4
#SBATCH --mem=200000
#SBATCH --gres=gpu:a100:1
#SBATCH -t 8:00:00


# Initialize CUDA environment
export CUDA_HOME=/usr/local/cuda-12.5
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export PATH=$CUDA_HOME/bin:$PATH

# Initialize Conda (adjust paths as needed)
source /home/ivieira/mambaforge/etc/profile.d/conda.sh
conda activate my-pip-env2

# Set GPU devices from SLURM
export CUDA_VISIBLE_DEVICES=$SLURM_STEP_GPUS

# Load HuggingFace token from a separate file that is not in git
source ~/.huggingface_token  # This file should contain: export HUGGINGFACEHUB_API_TOKEN='your_token'

# Clean up any problematic packages before running
pip uninstall -y tyro transformers peft trl
pip cache purge

# Run the script
python run_llama_factory.py
