#!/bin/bash
#SBATCH -p compute
#SBATCH -J llama_factory
#SBATCH --cpus-per-task=4
#SBATCH --mem=200000
#SBATCH --gres=gpu:a100:1
#SBATCH -t 8:00:00
#SBATCH -o llama_factory_%j.out
#SBATCH -e llama_factory_%j.err

# Initialize CUDA environment
export CUDA_HOME=/usr/local/cuda-12.5
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export PATH=$CUDA_HOME/bin:$PATH

# Initialize Conda
source /home/ivieira/mambaforge/etc/profile.d/conda.sh

# Clean up and create fresh environment
conda deactivate
conda env remove -n llama-env -y
conda clean -a -y  # Clean all conda caches
conda create -n llama-env python=3.8 -y
conda activate llama-env

# Install PyTorch using pip instead of conda
pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Set GPU devices from SLURM
export CUDA_VISIBLE_DEVICES=$SLURM_STEP_GPUS

# Load HuggingFace token from a separate file that is not in git
source ~/.huggingface_token

# Run the script
python run_llama_factory.py
