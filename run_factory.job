#!/bin/bash
#SBATCH -p compute
#SBATCH -J llama_factory
#SBATCH --cpus-per-task=4
#SBATCH --mem=200000
#SBATCH --gres=gpu:a100:1
#SBATCH -t 8:00:00

# Initialize CUDA environment
export CUDA_HOME=/usr/local/cuda-12.5
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export PATH=$CUDA_HOME/bin:$PATH

# Initialize Conda
source /home/ivieira/mambaforge/etc/profile.d/conda.sh

# Create and activate a new conda environment if it doesn't exist
conda create -n llama-env python=3.8 -y
conda activate llama-env

# Install basic requirements
conda install -y pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# Set GPU devices from SLURM
export CUDA_VISIBLE_DEVICES=$SLURM_STEP_GPUS

# Load HuggingFace token from a separate file that is not in git
source ~/.huggingface_token

# Run the script
python run_llama_factory.py
